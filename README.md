# ToyKernel

Common CUDA kernel implementations from scratch. ä»é›¶å­¦ä¹  CUDA é«˜æ€§èƒ½ç®—å­å®ç°ã€‚

## ğŸ¯ Roadmap

| Phase | Operators | Description | Status |
|-------|-----------|-------------|--------|
| **Phase 1: Basics** | | åŸºç¡€ç®—å­ | |
| | Vector Add | å‘é‡ç›¸åŠ  | â¬œ |
| | Matrix Multiply | çŸ©é˜µä¹˜æ³• (Naive) | â¬œ |
| | Softmax | Softmax è®¡ç®— | â¬œ |
| **Phase 2: GEMM** | | çŸ©é˜µä¹˜æ³•ä¼˜åŒ– | |
| | GEMM (Tiled) | åˆ†å—çŸ©é˜µä¹˜æ³• | â¬œ |
| | GEMM (Shared Memory) | å…±äº«å†…å­˜ä¼˜åŒ– | â¬œ |
| | GEMM (Tensor Cores) | Tensor Core åŠ é€Ÿ | â¬œ |
| **Phase 3: Attention** | | Attention å˜ä½“ | |
| | FlashAttention-2 | å‰å‘ä¼ æ’­ | â¬œ |
| | FlashAttention-2 (Backward) | åå‘ä¼ æ’­ | â¬œ |
| | FlashDecoding | æ¨ç†è§£ç ä¼˜åŒ– | â¬œ |
| **Phase 4: Advanced** | | è¿›é˜¶ç®—å­ | |
| | RoPE | ä½ç½®ç¼–ç  | â¬œ |
| | LayerNorm | å±‚å½’ä¸€åŒ– | â¬œ |
| | RMSNorm | RMS å½’ä¸€åŒ– | â¬œ |
| | GeLU | æ¿€æ´»å‡½æ•° | â¬œ |

## ğŸ“ Project Structure

```
toykernel/
â”œâ”€â”€ README.md
â”œâ”€â”€ src/                    # Kernel å®ç°
â”‚   â”œâ”€â”€ basics/            # åŸºç¡€ç®—å­
â”‚   â”‚   â”œâ”€â”€ vector_add.cu
â”‚   â”‚   â””â”€â”€ softmax.cu
â”‚   â”œâ”€â”€ gemm/               # çŸ©é˜µä¹˜æ³•
â”‚   â”‚   â”œâ”€â”€ naive_gemm.cu
â”‚   â”‚   â”œâ”€â”€ tiled_gemm.cu
â”‚   â”‚   â””â”€â”€ tensor_core_gemm.cu
â”‚   â”œâ”€â”€ attention/         # Attention ç³»åˆ—
â”‚   â”‚   â”œâ”€â”€ flash_attention.cu
â”‚   â”‚   â””â”€â”€ flash_decoding.cu
â”‚   â””â”€â”€ norm/              # å½’ä¸€åŒ–å±‚
â”‚       â”œâ”€â”€ layernorm.cu
â”‚       â””â”€â”€ rmsnorm.cu
â”œâ”€â”€ include/               # å¤´æ–‡ä»¶
â”‚   â””â”€â”€ utils.cuh
â”œâ”€â”€ tests/                 # å•å…ƒæµ‹è¯•
â”œâ”€â”€ benchmarks/           # æ€§èƒ½æµ‹è¯•
â””â”€â”€ scripts/              # ç¼–è¯‘è„šæœ¬
```

## ğŸš€ Quick Start

### ç¯å¢ƒè¦æ±‚

- CUDA Toolkit 12.x+
- CMake 3.18+
- GCC 11+
- NVIDIA GPU (sm_80+ for Tensor Cores)

### ç¼–è¯‘

```bash
mkdir build && cd build
cmake .. -DCMAKE_CUDA_ARCHITECTURES=80
make -j$(nproc)
```

### è¿è¡Œæµ‹è¯•

```bash
./tests/basic_test
./benchmarks/gemm_benchmark
```

## ğŸ“Š Reference

- [CUDA C Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
- [FlashAttention Paper](https://arxiv.org/abs/2205.14135)
- [FlashDecoding Paper](https://arxiv.org/abs/2309.06169)
- [ CUTLASS](https://github.com/NVIDIA/cutlass)
- [TinyCUDA](https://github.com/eynnzerr/TinyCUDA)

## ğŸ¤ Contributing

1. Fork this repo
2. Create your feature branch (`git checkout -b feature/xxx`)
3. Commit with proper template (`git commit` will auto-use template)
4. Push to branch
5. Open a Pull Request

## ğŸ“ License

MIT License

---

*Learning by doing. çº¸ä¸Šå¾—æ¥ç»ˆè§‰æµ…ï¼Œç»çŸ¥æ­¤äº‹è¦èº¬è¡Œã€‚*
